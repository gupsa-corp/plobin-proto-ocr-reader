from fastapi import APIRouter, File, UploadFile, HTTPException, Query
from typing import List, Optional
from pathlib import Path
import tempfile
import shutil
import time
import os
from datetime import datetime

from api.models.schemas import ProcessingResult, BlockInfo
from services.file.request_manager import generate_request_metadata, create_request_structure, create_page_structure, create_block_file_path
from services.file.storage import RequestStorage
from services.ocr.extraction import crop_all_blocks

router = APIRouter()

# Global dependencies that will be injected
server_stats = None
extractor = None
pdf_processor = None
output_dir = None

def set_dependencies(stats, doc_extractor, pdf_proc, out_dir=None):
    global server_stats, extractor, pdf_processor, output_dir
    server_stats = stats
    extractor = doc_extractor
    pdf_processor = pdf_proc
    output_dir = out_dir or "output"

@router.post("/process-pdf")
async def process_pdf(
    file: UploadFile = File(...),
    merge_blocks: Optional[bool] = Query(True, description="ì¸ì ‘í•œ ë¸”ë¡ë“¤ì„ ë³‘í•©í•˜ì—¬ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”"),
    merge_threshold: Optional[int] = Query(30, description="ë¸”ë¡ ë³‘í•© ì„ê³„ê°’ (í”½ì…€ ë‹¨ìœ„)"),
    create_sections: Optional[bool] = Query(False, description="ë¸”ë¡ë“¤ì„ ë…¼ë¦¬ì  ì„¹ì…˜ìœ¼ë¡œ ê·¸ë£¹í™” (header, body, footer ë“±)"),
    build_hierarchy_tree: Optional[bool] = Query(False, description="ë¸”ë¡ ê°„ ê³„ì¸µ êµ¬ì¡° êµ¬ì¶• (í¬í•¨ ê´€ê³„)")
):
    start_time = time.time()
    server_stats["total_requests"] += 1
    server_stats["last_request_time"] = datetime.now()

    if not file.content_type or file.content_type != 'application/pdf':
        server_stats["errors"] += 1
        raise HTTPException(status_code=400, detail="File must be a PDF")

    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            shutil.copyfileobj(file.file, tmp_file)
            tmp_path = tmp_file.name

        try:
            # íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            file_stats = os.stat(tmp_path)
            file_size = file_stats.st_size

            with tempfile.TemporaryDirectory() as temp_dir:
                print(f"ğŸ”„ PDF ë³€í™˜ ì‹œì‘: {file.filename}")
                image_paths = pdf_processor.convert_pdf_to_images(tmp_path, temp_dir)
                total_pages = len(image_paths)
                print(f"âœ… PDF ë³€í™˜ ì™„ë£Œ: {total_pages} í˜ì´ì§€")

                # RequestStorageë¥¼ ì‚¬ìš©í•´ì„œ ì €ì¥
                storage = RequestStorage(output_dir)

                # ìš”ì²­ ìƒì„±
                request_id = storage.create_request(file.filename, "pdf", file_size, total_pages=total_pages)

                # í˜ì´ì§€ë³„ ì²˜ë¦¬ ë° ì €ì¥
                all_pages_data = []
                total_blocks_count = 0
                total_confidence_sum = 0

                for i, image_path in enumerate(image_paths):
                    page_num = i + 1
                    page_start_time = time.time()
                    print(f"ğŸ”„ í˜ì´ì§€ {page_num} OCR ì²˜ë¦¬ ì‹œì‘...")

                    result = extractor.extract_blocks(
                        image_path,
                        merge_blocks=merge_blocks,
                        merge_threshold=merge_threshold,
                        create_sections=create_sections,
                        build_hierarchy_tree=build_hierarchy_tree
                    )
                    blocks = result.get('blocks', [])
                    page_processing_time = time.time() - page_start_time

                    # ë©”íƒ€ë°ì´í„° ì¤€ë¹„ (ì„¹ì…˜/ê³„ì¸µ ì •ë³´ í¬í•¨)
                    ocr_metadata = {}
                    if create_sections and 'sections' in result:
                        ocr_metadata['sections'] = result['sections']
                        ocr_metadata['section_summary'] = result.get('section_summary', {})

                    if build_hierarchy_tree and 'hierarchical_blocks' in result:
                        ocr_metadata['hierarchical_blocks'] = result['hierarchical_blocks']
                        ocr_metadata['hierarchy_statistics'] = result.get('hierarchy_statistics', {})

                    # í˜ì´ì§€ ê²°ê³¼ ì €ì¥
                    storage.save_page_result(request_id, page_num, blocks, page_processing_time, metadata=ocr_metadata if ocr_metadata else None)

                    # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ (PDFì—ì„œ ë³€í™˜ëœ í˜ì´ì§€ ì´ë¯¸ì§€)
                    try:
                        storage.save_original_image(request_id, page_num, image_path)
                    except Exception as e:
                        print(f"í˜ì´ì§€ {page_num} ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")

                    # ë¸”ë¡ë³„ ì´ë¯¸ì§€ í¬ë¡­ ë° ì €ì¥
                    if blocks:
                        try:
                            cropped_blocks = crop_all_blocks(image_path, blocks, padding=5)
                            storage.save_block_images(request_id, page_num, cropped_blocks)
                        except Exception as e:
                            print(f"í˜ì´ì§€ {page_num} ë¸”ë¡ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")

                    # ì‹œê°í™” ì €ì¥
                    if blocks:
                        try:
                            request_dir = Path(output_dir) / request_id
                            viz_path = request_dir / "pages" / f"{page_num:03d}" / "visualization.png"
                            extractor.visualize_blocks(image_path, {'blocks': blocks}, str(viz_path))
                        except Exception as e:
                            print(f"í˜ì´ì§€ {page_num} ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")

                    # í†µê³„ ëˆ„ì 
                    total_blocks_count += len(blocks)
                    if blocks:
                        page_confidence = sum(block.get('confidence', 0) for block in blocks) / len(blocks)
                        total_confidence_sum += page_confidence
                        all_pages_data.append({
                            "page_number": page_num,
                            "total_blocks": len(blocks),
                            "average_confidence": round(page_confidence, 3),
                            "processing_time": round(page_processing_time, 3)
                        })
                    else:
                        all_pages_data.append({
                            "page_number": page_num,
                            "total_blocks": 0,
                            "average_confidence": 0.0,
                            "processing_time": round(page_processing_time, 3)
                        })

                # ìš”ì²­ ì™„ë£Œ ì²˜ë¦¬
                processing_time = time.time() - start_time
                overall_confidence = total_confidence_sum / max(len([p for p in all_pages_data if p["total_blocks"] > 0]), 1)

                summary_data = {
                    "total_pages": total_pages,
                    "total_blocks": total_blocks_count,
                    "overall_confidence": round(overall_confidence, 3),
                    "processing_time": round(processing_time, 3),
                    "pages": all_pages_data,
                    "completed_at": datetime.now().isoformat(),
                    "sections_created": create_sections,
                    "hierarchy_built": build_hierarchy_tree
                }
                storage.complete_request(request_id, summary_data)

                # í†µê³„ ì—…ë°ì´íŠ¸
                server_stats["total_pdfs_processed"] += 1
                server_stats["total_blocks_extracted"] += total_blocks_count
                server_stats["total_processing_time"] += processing_time

                return {
                    "request_id": request_id,
                    "status": "completed",
                    "original_filename": file.filename,
                    "file_type": "pdf",
                    "file_size": file_size,
                    "total_pages": total_pages,
                    "processing_time": round(processing_time, 3),
                    "processing_url": f"/requests/{request_id}"
                }

        finally:
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)

    except Exception as e:
        server_stats["errors"] += 1
        import traceback
        error_details = {
            "error": str(e),
            "error_type": type(e).__name__,
            "traceback": traceback.format_exc(),
            "filename": file.filename if file else "unknown",
            "request_id": request_id if 'request_id' in locals() else "unknown"
        }
        print(f"âŒ PDF ì²˜ë¦¬ ì˜¤ë¥˜: {error_details}")

        # íŒŒì´í”„ ì˜¤ë¥˜ íŠ¹ë³„ ì²˜ë¦¬
        if "Broken pipe" in str(e) or "íŒŒì´í”„ê°€ ê¹¨ì–´ì§" in str(e):
            print(f"ğŸ” íŒŒì´í”„ ì˜¤ë¥˜ ë””ë²„ê¹… ì •ë³´:")
            print(f"   - ì„ì‹œ íŒŒì¼ ê²½ë¡œ: {tmp_path if 'tmp_path' in locals() else 'unknown'}")
            print(f"   - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
            print(f"   - í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")

        raise HTTPException(status_code=500, detail=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@router.post("/process-document")
async def process_document(file: UploadFile = File(...)):
    """ë²”ìš© ë¬¸ì„œ ì²˜ë¦¬ (ì´ë¯¸ì§€/PDF ìë™ ê°ì§€)"""
    content_type = file.content_type or ""

    if content_type == 'application/pdf':
        return await process_pdf(file)
    elif content_type.startswith('image/'):
        from api.endpoints.process_image import process_image
        return await process_image(file)
    else:
        raise HTTPException(
            status_code=400,
            detail="File must be an image (JPEG, PNG, etc.) or PDF"
        )